{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMf7N5R1FdcR4HJ7F+0CCCN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SidU/LLMs-from-scratch/blob/main/Embeddings.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Continuous Bag of Words (CBOW) Example Using PyTorch\n",
        "\n",
        "This notebook demonstrates how CBOW works using PyTorch. It includes:\n",
        "1. Vocabulary and embedding matrix setup.\n",
        "2. Retrieving embeddings for context words.\n",
        "3. Averaging context embeddings.\n",
        "4. Predicting the target word and updating embeddings."
      ],
      "metadata": {
        "id": "83TC61IQDmx1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import libraries\n"
      ],
      "metadata": {
        "id": "6Rs9w3_oDp-B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim"
      ],
      "metadata": {
        "id": "Albr892LDt03"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Vocabulary and Embedding Matrix\n",
        "We'll start by defining a small vocabulary of 4 words \"cat\", \"dog\", \"mouse\", and \"cheese\" and an embedding size of 3.\n",
        "An embedding layer will store random embeddings for each word initially."
      ],
      "metadata": {
        "id": "Ld7UYF6ZDzVw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define vocabulary and embedding dimensions\n",
        "vocab = [\"cat\", \"dog\", \"mouse\", \"cheese\"]\n",
        "vocab_size = len(vocab)  # Vocabulary size\n",
        "embedding_dim = 3  # Embedding dimensions\n",
        "\n",
        "# Embedding layer\n",
        "embedding_layer = nn.Embedding(vocab_size, embedding_dim)\n",
        "\n",
        "# Initialize the embedding matrix randomly\n",
        "torch.manual_seed(42)  # For reproducibility\n",
        "print(\"Initial Embedding Matrix:\")\n",
        "print(embedding_layer.weight.data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eFYPzdZZD1yi",
        "outputId": "ee855881-34d3-42d0-b3b7-7eec1f29fcbd"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial Embedding Matrix:\n",
            "tensor([[ 0.4617,  0.2674,  0.5349],\n",
            "        [ 0.8094,  1.1103, -1.6898],\n",
            "        [-0.9890,  0.9580,  1.3221],\n",
            "        [ 0.8172, -0.7658, -0.7506]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Context Words and Target Word\n",
        "We define two context words (`\"dog\"` and `\"mouse\"`) and a target word (`\"cat\"`).\n",
        "Context words help predict the target word."
      ],
      "metadata": {
        "id": "3lywXol5EEIP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define context and target words\n",
        "context_words = [\"dog\", \"mouse\"]  # Context words\n",
        "target_word = \"cat\"  # Target word\n",
        "\n",
        "# Map words to indices\n",
        "word_to_idx = {word: idx for idx, word in enumerate(vocab)}\n",
        "idx_to_word = {idx: word for word, idx in word_to_idx.items()}\n",
        "\n",
        "# Convert context words to indices\n",
        "context_indices = torch.tensor([word_to_idx[word] for word in context_words])  # [1, 2]\n",
        "print(\"Context Indices:\", context_indices)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kc1lfY9OEJl-",
        "outputId": "f2760a19-e8c3-435b-f464-00d9944e7e94"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Context Indices: tensor([1, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Retrieve Embeddings for Context Words\n",
        "Using the indices of the context words, we retrieve their embeddings from the embedding matrix."
      ],
      "metadata": {
        "id": "ZAJFTDuzEVVT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Look up embeddings for context words\n",
        "context_embeddings = embedding_layer(context_indices)\n",
        "print(\"Context Embeddings:\")\n",
        "print(context_embeddings)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vHY8AoABEXYk",
        "outputId": "a107104f-9867-4200-bb75-23d86fd79318"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Context Embeddings:\n",
            "tensor([[ 0.8094,  1.1103, -1.6898],\n",
            "        [-0.9890,  0.9580,  1.3221]], grad_fn=<EmbeddingBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Averaging Context Embeddings\n",
        "We average the embeddings for context words to form the **context vector**,\n",
        "which represents the context of the sentence."
      ],
      "metadata": {
        "id": "M7MoVpC4EdSN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Average the embeddings to get the context vector\n",
        "context_vector = context_embeddings.mean(dim=0) # dim=0 means average along the rows\n",
        "print(\"Averaged Context Vector:\")\n",
        "print(context_vector)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W2WOI7DcEfYR",
        "outputId": "29cc5f5c-da61-412c-f240-f8b12660f8cc"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Averaged Context Vector:\n",
            "tensor([-0.0898,  1.0341, -0.1838], grad_fn=<MeanBackward1>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Predict the Target Word\n",
        "The averaged context vector is passed through a linear layer to predict the target word.\n",
        "The output is converted into probabilities using the softmax function."
      ],
      "metadata": {
        "id": "DhEN9skyE_Nk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Output layer to map context vector to vocabulary\n",
        "output_layer = nn.Linear(embedding_dim, vocab_size)\n",
        "\n",
        "# Predict target word\n",
        "output_logits = output_layer(context_vector)\n",
        "output_probs = nn.Softmax(dim=-1)(output_logits)\n",
        "print(\"Predicted Probabilities for Vocabulary Words:\")\n",
        "print({idx_to_word[i]: p for i, p in enumerate(output_probs.tolist())})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fwh-D0siFBpT",
        "outputId": "b8219e76-ad3c-4a1c-9b9e-25cbcf6804a1"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Probabilities for Vocabulary Words:\n",
            "{'cat': 0.3702388107776642, 'dog': 0.1323089450597763, 'mouse': 0.26178431510925293, 'cheese': 0.23566798865795135}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loss Computation and Backpropagation\n",
        "We compute the cross-entropy loss between the predicted probabilities and the true target word.\n",
        "The embedding matrix and linear layer are updated using backpropagation."
      ],
      "metadata": {
        "id": "NE2wTjO4FXnP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define target index\n",
        "target_index = torch.tensor([word_to_idx[target_word]])  # Index of \"cat\"\n",
        "\n",
        "# Loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(list(embedding_layer.parameters()) + list(output_layer.parameters()), lr=0.1)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(10):  # Number of epochs\n",
        "    optimizer.zero_grad()  # Clear previous gradients\n",
        "\n",
        "    # Recompute context embeddings for the current parameters\n",
        "    context_embeddings = embedding_layer(context_indices)  # Get embeddings for context words\n",
        "    context_vector = context_embeddings.mean(dim=0)  # Average context embeddings\n",
        "\n",
        "    # Forward pass\n",
        "    output_logits = output_layer(context_vector)\n",
        "    loss = criterion(output_logits.unsqueeze(0), target_index)  # Compute loss\n",
        "\n",
        "    # Backpropagation\n",
        "    loss.backward()\n",
        "    optimizer.step()  # Update parameters\n",
        "\n",
        "    # Print loss for each epoch\n",
        "    print(f\"Epoch {epoch + 1}, Loss: {loss.item()}\")\n",
        "\n",
        "# Check updated embedding matrix\n",
        "print(\"Updated Embedding Matrix:\")\n",
        "print(embedding_layer.weight.data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ysbz5M0cFZWO",
        "outputId": "5f05a1aa-39c0-47e7-c463-fe20b0c48a2f"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 0.9936070442199707\n",
            "Epoch 2, Loss: 0.8731562495231628\n",
            "Epoch 3, Loss: 0.7691994309425354\n",
            "Epoch 4, Loss: 0.6796515583992004\n",
            "Epoch 5, Loss: 0.602611780166626\n",
            "Epoch 6, Loss: 0.5363603234291077\n",
            "Epoch 7, Loss: 0.479358434677124\n",
            "Epoch 8, Loss: 0.4302491545677185\n",
            "Epoch 9, Loss: 0.38785070180892944\n",
            "Epoch 10, Loss: 0.35114580392837524\n",
            "Updated Embedding Matrix:\n",
            "tensor([[ 0.4617,  0.2674,  0.5349],\n",
            "        [ 0.9373,  1.2150, -1.7927],\n",
            "        [-0.8611,  1.0626,  1.2192],\n",
            "        [ 0.8172, -0.7658, -0.7506]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test Phase: Verify the Modelâ€™s Learning\n",
        "\n",
        "After training, we test the model to ensure it has learned the relationship between the context words and the target word.\n",
        "\n",
        "In this test, we use the trained embeddings and output layer to:\n",
        "\n",
        "1.\tRecompute the context vector from the test context words (\"dog\" and \"mouse\").\n",
        "2.\tPredict the target word (\"cat\") using the trained model.\n",
        "3.\tCompare the predicted word with the actual target word to check if the model learned correctly.\n",
        "\n",
        "The test phase does not update the model weights, and no gradients are computed during this process."
      ],
      "metadata": {
        "id": "8J2eAGmZGqbj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Test phase\n",
        "embedding_layer.eval()  # Set embedding layer to evaluation mode\n",
        "output_layer.eval()  # Set output layer to evaluation mode\n",
        "\n",
        "# Test context words and target\n",
        "test_context_words = [\"dog\", \"mouse\"]\n",
        "test_context_indices = torch.tensor([word_to_idx[word] for word in test_context_words])  # Indices for \"dog\" and \"mouse\"\n",
        "\n",
        "# Recompute context vector for test context\n",
        "with torch.no_grad():  # Disable gradient computations during testing\n",
        "    test_context_embeddings = embedding_layer(test_context_indices)  # Get embeddings for test context\n",
        "    test_context_vector = test_context_embeddings.mean(dim=0)  # Average embeddings\n",
        "\n",
        "    # Predict the target word\n",
        "    test_logits = output_layer(test_context_vector)  # Forward pass\n",
        "    test_probs = nn.Softmax(dim=-1)(test_logits)  # Compute probabilities\n",
        "    predicted_index = torch.argmax(test_probs).item()  # Get the index of the highest probability word\n",
        "    predicted_word = idx_to_word[predicted_index]  # Map index to word\n",
        "\n",
        "# Print the test result\n",
        "print(f\"Context Words: {test_context_words}\")\n",
        "print(f\"Predicted Word: {predicted_word}\")\n",
        "print(f\"Actual Target Word: {target_word}\")\n",
        "\n",
        "# Check if the prediction matches the target word\n",
        "if predicted_word == target_word:\n",
        "    print(\"The model correctly predicted the target word!\")\n",
        "else:\n",
        "    print(\"The model failed to predict the target word.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DwuOC44uGu19",
        "outputId": "cd86964c-af26-4600-876b-f8ca7a4b2d95"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Context Words: ['dog', 'mouse']\n",
            "Predicted Word: cat\n",
            "Actual Target Word: cat\n",
            "The model correctly predicted the target word!\n"
          ]
        }
      ]
    }
  ]
}